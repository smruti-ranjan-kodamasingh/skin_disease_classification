{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/smruti/projects/skin_disease_classification/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/smruti/projects/skin_disease_classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 09:21:16.370175: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-08 09:21:16.415294: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from skin_disease_classifier.constants import *\n",
    "from skin_disease_classifier.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"dataset\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "    \n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        data_dir = self.config.training_data\n",
    "        seed = 123\n",
    "\n",
    "        # Splitting data and creating training and validation datasets\n",
    "        self.train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "            data_dir,\n",
    "            validation_split=0.1,\n",
    "            subset=\"training\",\n",
    "            seed=seed,\n",
    "            image_size=(self.config.params_image_size[0], self.config.params_image_size[1]),\n",
    "            batch_size=self.config.params_batch_size\n",
    "        )\n",
    "\n",
    "        self.validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "            data_dir,\n",
    "            validation_split=0.1,\n",
    "            subset=\"validation\",\n",
    "            seed=seed,\n",
    "            image_size=(self.config.params_image_size[0], self.config.params_image_size[1]),\n",
    "            batch_size=self.config.params_batch_size\n",
    "        )\n",
    "\n",
    "        # Normalizing Pixel Values for Training and Validation Datasets\n",
    "        self.train_ds = self.train_ds.map(lambda x, y: (x / 255.0, y))\n",
    "        self.validation_ds = self.validation_ds.map(lambda x, y: (x / 255.0, y))\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=10,\n",
    "            verbose=1,\n",
    "            mode='max',\n",
    "            restore_best_weights=True,\n",
    "            baseline=0.98\n",
    "        )\n",
    "\n",
    "        self.model.fit(\n",
    "            self.train_ds,\n",
    "            epochs=self.config.params_epochs,\n",
    "            validation_data=self.validation_ds,\n",
    "            callbacks=[early_stopping]\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-08 09:21:18,429: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-03-08 09:21:18,431: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-03-08 09:21:18,432: INFO: common: created directory at: artifacts]\n",
      "[2025-03-08 09:21:18,434: INFO: common: created directory at: artifacts/training]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 09:21:18.467231: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-08 09:21:18.472917: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-08 09:21:18.472953: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-08 09:21:18.476805: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-08 09:21:18.476839: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-08 09:21:18.476851: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-08 09:21:18.552614: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-08 09:21:18.552655: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-08 09:21:18.552661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-03-08 09:21:18.552682: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-08 09:21:18.552706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/smruti/miniconda3/envs/tf216/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9548 files belonging to 5 classes.\n",
      "Using 8594 files for training.\n",
      "Found 9548 files belonging to 5 classes.\n",
      "Using 954 files for validation.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741425690.053562   23001 service.cc:145] XLA service 0x7f22cc002970 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741425690.053629   23001 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-03-08 09:21:30.536461: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-03-08 09:21:32.646749: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2025-03-08 09:21:40.219578: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng55{k2=0,k13=2,k14=2,k18=0,k22=0,k23=1} for conv (f32[32,128,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,192,56,56]{3,2,1,0}, f32[128,192,1,1]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2025-03-08 09:21:40.222005: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.998664768s\n",
      "Trying algorithm eng55{k2=0,k13=2,k14=2,k18=0,k22=0,k23=1} for conv (f32[32,128,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,192,56,56]{3,2,1,0}, f32[128,192,1,1]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/269\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:27:05\u001b[0m 33s/step - accuracy: 0.2188 - loss: 2.2955"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741425715.561711   23001 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7397 - loss: 0.7272"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 09:22:48.675900: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k2=2,k6=2,k13=2,k14=0,k22=1} for conv (f32[26,128,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[26,224,56,56]{3,2,1,0}, f32[128,224,1,1]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2025-03-08 09:22:48.685044: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.062583988s\n",
      "Trying algorithm eng48{k2=2,k6=2,k13=2,k14=0,k22=1} for conv (f32[26,128,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[26,224,56,56]{3,2,1,0}, f32[128,224,1,1]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 249ms/step - accuracy: 0.7400 - loss: 0.7263 - val_accuracy: 0.9109 - val_loss: 0.2451\n",
      "Epoch 2/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 83ms/step - accuracy: 0.9042 - loss: 0.2604 - val_accuracy: 0.9560 - val_loss: 0.1374\n",
      "Epoch 3/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 71ms/step - accuracy: 0.9264 - loss: 0.2068 - val_accuracy: 0.9539 - val_loss: 0.1188\n",
      "Epoch 4/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 85ms/step - accuracy: 0.9382 - loss: 0.1654 - val_accuracy: 0.9560 - val_loss: 0.1172\n",
      "Epoch 5/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 77ms/step - accuracy: 0.9412 - loss: 0.1569 - val_accuracy: 0.9696 - val_loss: 0.0845\n",
      "Epoch 6/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 83ms/step - accuracy: 0.9588 - loss: 0.1164 - val_accuracy: 0.9801 - val_loss: 0.0735\n",
      "Epoch 7/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - accuracy: 0.9592 - loss: 0.1141 - val_accuracy: 0.9717 - val_loss: 0.0874\n",
      "Epoch 8/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 78ms/step - accuracy: 0.9634 - loss: 0.1009 - val_accuracy: 0.9780 - val_loss: 0.0712\n",
      "Epoch 9/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 83ms/step - accuracy: 0.9672 - loss: 0.0853 - val_accuracy: 0.9727 - val_loss: 0.0740\n",
      "Epoch 10/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 90ms/step - accuracy: 0.9745 - loss: 0.0730 - val_accuracy: 0.9811 - val_loss: 0.0589\n",
      "Epoch 11/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - accuracy: 0.9726 - loss: 0.0726 - val_accuracy: 0.9874 - val_loss: 0.0446\n",
      "Epoch 12/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - accuracy: 0.9743 - loss: 0.0703 - val_accuracy: 0.9822 - val_loss: 0.0478\n",
      "Epoch 13/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 90ms/step - accuracy: 0.9800 - loss: 0.0589 - val_accuracy: 0.9801 - val_loss: 0.0624\n",
      "Epoch 14/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 77ms/step - accuracy: 0.9811 - loss: 0.0578 - val_accuracy: 0.9717 - val_loss: 0.0727\n",
      "Epoch 15/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 88ms/step - accuracy: 0.9731 - loss: 0.0735 - val_accuracy: 0.9727 - val_loss: 0.0694\n",
      "Epoch 16/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 84ms/step - accuracy: 0.9823 - loss: 0.0544 - val_accuracy: 0.9843 - val_loss: 0.0552\n",
      "Epoch 17/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 79ms/step - accuracy: 0.9835 - loss: 0.0464 - val_accuracy: 0.9864 - val_loss: 0.0449\n",
      "Epoch 18/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 85ms/step - accuracy: 0.9767 - loss: 0.0607 - val_accuracy: 0.9895 - val_loss: 0.0373\n",
      "Epoch 19/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 88ms/step - accuracy: 0.9822 - loss: 0.0429 - val_accuracy: 0.9853 - val_loss: 0.0555\n",
      "Epoch 20/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 77ms/step - accuracy: 0.9813 - loss: 0.0544 - val_accuracy: 0.9832 - val_loss: 0.0641\n",
      "Epoch 21/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - accuracy: 0.9828 - loss: 0.0518 - val_accuracy: 0.9801 - val_loss: 0.0592\n",
      "Epoch 22/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - accuracy: 0.9862 - loss: 0.0398 - val_accuracy: 0.9843 - val_loss: 0.0509\n",
      "Epoch 23/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 79ms/step - accuracy: 0.9874 - loss: 0.0383 - val_accuracy: 0.9780 - val_loss: 0.0669\n",
      "Epoch 24/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - accuracy: 0.9845 - loss: 0.0458 - val_accuracy: 0.9853 - val_loss: 0.0419\n",
      "Epoch 25/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - accuracy: 0.9872 - loss: 0.0340 - val_accuracy: 0.9832 - val_loss: 0.0569\n",
      "Epoch 26/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 78ms/step - accuracy: 0.9858 - loss: 0.0407 - val_accuracy: 0.9832 - val_loss: 0.0513\n",
      "Epoch 27/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 88ms/step - accuracy: 0.9884 - loss: 0.0327 - val_accuracy: 0.9822 - val_loss: 0.0583\n",
      "Epoch 28/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - accuracy: 0.9894 - loss: 0.0301 - val_accuracy: 0.9822 - val_loss: 0.0523\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf216",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
